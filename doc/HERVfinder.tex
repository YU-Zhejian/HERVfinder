\documentclass[9pt,final,journal,twocolumn,a4paper]{IEEEtran}

\title{HERVfinder -- A BLAST-Based Multi-Thread HERV Finder}
\author{Group 12}
% \IEEEspecialpapernotice{Proposal}

% \IEEEpubid{Proposal}

\newcommand{\warn}{\textbf{WARNING:}\space}
\newcommand{\info}{\textbf{INFO:}\space}
\usepackage{fancyvrb}
\usepackage{minted}
\fvset{numbers=left,fontsize=\fontsize{8}{10}\selectfont,numbersep=6pt}

\usepackage{nth}
\usepackage{hologo}
\usepackage{float}
\usepackage{hyperref}
\begin{document}
\sloppy{}\flushbottom\maketitle\tableofcontents
\section{Introduction}

\IEEEPARstart{H}{uman} Endogenous Retroviruses (HERV) are a family of viruses inside the human genome produced by ancient retroviral infection. It is important to locate them inside the human genome since they are proven to be related to cancer and other diseases.

The problem of finding HERV inside the human genome can be considered as a problem of \textbf{un-gapped sequence alignment} or \textbf{state prediction}. Approach to the first problem may consider Basic Local Alignment Search Tool (BLAST)-like seed-and-extend algorithms or suffix tree with mismatch using Burrows-Wheeler Transform (BWT) with Ferragina-Manzini (FM) Index, with another using machine-learning based approach like Hidden Markov Models (HMM).

So, we proposed to develop \verb|HERVfinder|, which is a bioinformatics software that can identify the HERV sequences inside the human reference genome or other genome assemblies in FASTA format. It will take HERV consensus sequence FASTA downloaded from Dfam and un- or soft-masked assembled human genome FASTA sequence as input, and produce a tabular file containing all HERV loci in BED or GTF format. This application should run on any computer with Python (CPython implementation) 3.7+. Users may also specify selected HERV types, the number of mismatches allowed or the number of threads used.


\section{Design of Algorithm}

The BLAST-alike algorithm used is a modified version of BLASTN, which is a heuristic seed-and-extend algorithm. Here, we refer to the HERV sequences as needles and the human reference genome as the haystack.

\subsection{The \textbf{Indexing} Phase}

The index is built with the purpose of finding all locations of a specific word in a short time.

As is known to us all, DNA sequences are combinations of 4 nucleotides. Here we refer a single nucleotide as a \textbf{letter}, and all possible values of the letters forms an \textbf{alphabet} of length $A$. We define \textbf{words} as combinations of defined number (called \textbf{word length}, $w$) of letters inside the alphabet. This alphabet can generate a \textbf{word set} of length $A^{w}$.

The \textbf{location} of a specific word inside a genome can be represented by tuple (chromosome, strand, starting-position). For example, the last position of chromosome 1 (which should be some tuple like \verb|(b'NC_000001.11', True, 249000000)| if using NCBI index) consumes 64 bytes of memory. The total memory consumption of chromosome 1 may raise up to 14.83GiB with 195.03GiB for the entire human genome\footnote{This is calculated from the data given by NCBI, with 3, 272.09Mbp genome length and 248.96Mbp chromosome 1 length.}.

With the sliding window method, we may build an  \textbf{simple index}, which is a hashmap with word as key and a list of locations of that key word inside a genome as value.

Based on the original BLAST article, $w$ is default to 11.

Low-complexity words are calculated by method TODO, and will be discarded.

\subsection{The \textbf{Anchoring} Phase}

\subsection{The \textbf{Extending} Phase}

\subsection{Parallelism}

Parallelism using multi-thread or multi-process is the core of the fast speed of BLAST and we never over-state its importance. Compared to single-threaded implementation, the multi-threaded approach is far more challenging by aspects like memory inconsistency, large memory use, inefficient scheduler and much much more.

Due to the existence of Global Interpretation Lock (GIL), the Python interpreter can execute only one Python machine code at a time, which makes multi-threading or co-routine useless for computation-intensive tasks. So, the general design of parallelism inside the algorithm is that for \textbf{computation-intensive tasks}, the program will use multi-process provided by \verb|multiprocessing| stdlib; for \textbf{IO-intensive tasks}, the program will use multi-threading provided by \verb|threading| stdlib. \verb|asyncio| stdlib is hard-to-use and may contaminate the entire program, so not used.



\section{Implementation}

\subsection{Ultilities}

\textbf{Compressed Pickle} is a module which can (de-)serialize Python objects using \verb|pickle| stdlib with Lempel-Ziv-Markov chain Algorithm version 2 (LZMA2) (de-)compression using \verb|lzma| stdlib on-the-fly. We design and implemented this module to save the disk space of the index.

\textbf{Parallel Job Queue} is a scheduler which accepts \verb|multiprocessing.Process| or \verb|threading.Thread| class as input and display a nice progress bar using \verb|tqdm|. We design and implement this module to overcome the limitations of \verb|multiprocessing.Pool| and \verb|concurrence.future|.

\subsection{The Indexing Phase}

FASTA file of the haystack is loaded into memory and split into \textbf{chunks} with \textbf{chunk length} at 2, 000, 000 bp. They are indexed in parallel. The \textbf{chunk-level indices} are further split by the leading $l$ bases, pickled and saved to a temporary directory. Once finished, the indices are re-joint by leading $l$ bases and are separately saved using compressed pickle.

\subsection{The Anchoring Phase}

The anchoring part of the algorithm is a single-threaded algorithm, providing an iterator of pairs of (chromosome, strand, starting-position) tuples as matching positions on needle and haystack.

\subsection{The Extending Phase}

They are then parallelly extended using Smith-Waterman-Gotoh-alike gap-aware local-alignment algorithms using dynamic programming. The extension is dropped if the score drops below a threshold, or accepted if the needle is found. The accepted loci are finally collected and transmitted to BED or GTF format and saved to disk.







\section{Discussion}

The algorithm BLAST is chosen for this project because its implementation is relatively easy. However, it is not that suitable to search for repetitive sequences. To overcome this problem, a second version using HMM is proposed. The HMM version includes generation of HMM from consensus sequence, apply it on the human reference genome and matrix acceleration using Numpy or Nvidia Cuda.

\end{document}
